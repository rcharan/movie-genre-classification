{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "import string\n",
    "import joblib\n",
    "import warnings\n",
    "import itertools\n",
    "import scipy.stats as st\n",
    "from math import sqrt\n",
    "import spacy\n",
    "import string\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "import sklearn.preprocessing           as pre\n",
    "import sklearn.pipeline                as pipe\n",
    "import sklearn.impute                  as imp\n",
    "import sklearn.compose                 as pipe2\n",
    "import sklearn.dummy                   as dum\n",
    "import sklearn.metrics                 as metr\n",
    "import sklearn.linear_model            as lm\n",
    "import sklearn.model_selection         as cv\n",
    "import sklearn.tree                    as tree\n",
    "import sklearn.ensemble                as ensem\n",
    "import sklearn.base                    as base\n",
    "# import sklearn.feature_extraction.text as text\n",
    "import sklearn.decomposition           as decomp\n",
    "import sklearn.naive_bayes             as bayes\n",
    "import sklearn.svm                     as svm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ioff()\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('talk')\n",
    "\n",
    "from utilities import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "col_rename = lambda df : df.rename(lambda s : s.lower().replace(' ', '_'), axis = 'columns')\n",
    "\n",
    "data           = col_rename(pd.read_csv('movie_train.csv', index_col=0))\n",
    "out_of_sample  = col_rename(pd.read_csv('movie_test.csv' , index_col=0))\n",
    "oos = out_of_sample # alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['action', 'adventure', 'comedy', 'crime', 'drama', 'horror',\n",
       "       'romance', 'thriller', 'western'], dtype='<U9')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the target\n",
    "label_binarizer = pre.LabelBinarizer()\n",
    "y_all = label_binarizer.fit_transform(data.genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the inputs\n",
    "seq_len = 512\n",
    "vocab_size = 20000\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(data['plot'])\n",
    "temp   = tokenizer.texts_to_sequences(data['plot'])\n",
    "X_all  = np.array(sequence.pad_sequences(temp, maxlen=seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(X_all, y_all, random_state = 42)\n",
    "\n",
    "# Alias\n",
    "X = X_train\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 512, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 512, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 2,614,153\n",
      "Trainable params: 2,614,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_size, input_length = seq_len),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(64, activation = 'relu', ),\n",
    "    Dropout(0.2),\n",
    "    Dense(9, activation = 'softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcharan/anaconda3/envs/learn37/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7209 samples, validate on 802 samples\n",
      "Epoch 1/10\n",
      "7209/7209 [==============================] - 304s 42ms/step - loss: 1.8937 - accuracy: 0.3412 - val_loss: 1.8550 - val_accuracy: 0.3404\n",
      "Epoch 2/10\n",
      "7209/7209 [==============================] - 304s 42ms/step - loss: 1.7344 - accuracy: 0.3612 - val_loss: 1.7637 - val_accuracy: 0.3404\n",
      "Epoch 3/10\n",
      "7209/7209 [==============================] - 296s 41ms/step - loss: 1.4684 - accuracy: 0.4497 - val_loss: 1.7889 - val_accuracy: 0.3703\n",
      "Epoch 4/10\n",
      "7209/7209 [==============================] - 291s 40ms/step - loss: 1.2086 - accuracy: 0.5655 - val_loss: 1.9500 - val_accuracy: 0.3541\n",
      "Epoch 5/10\n",
      "7209/7209 [==============================] - 293s 41ms/step - loss: 0.9594 - accuracy: 0.6622 - val_loss: 2.0935 - val_accuracy: 0.3741\n",
      "Epoch 6/10\n",
      "7209/7209 [==============================] - 318s 44ms/step - loss: 0.7558 - accuracy: 0.7388 - val_loss: 2.3356 - val_accuracy: 0.3778\n",
      "Epoch 7/10\n",
      "7209/7209 [==============================] - 305s 42ms/step - loss: 0.5805 - accuracy: 0.7994 - val_loss: 2.4973 - val_accuracy: 0.3616\n",
      "Epoch 8/10\n",
      "7209/7209 [==============================] - 269s 37ms/step - loss: 0.4337 - accuracy: 0.8578 - val_loss: 2.7608 - val_accuracy: 0.3890\n",
      "Epoch 9/10\n",
      "7209/7209 [==============================] - 335s 47ms/step - loss: 0.3108 - accuracy: 0.8994 - val_loss: 3.0396 - val_accuracy: 0.3716\n",
      "Epoch 10/10\n",
      "7209/7209 [==============================] - 289s 40ms/step - loss: 0.2478 - accuracy: 0.9204 - val_loss: 3.1684 - val_accuracy: 0.3828\n",
      "3009.618 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "# Timer.start()\n",
    "# model.fit(X, y, epochs=10, batch_size=64, validation_split=0.1, )\n",
    "# Timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/lstm-10.joblib']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, './models/lstm-10.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.7190595e-05, 6.3265958e-07, 9.1674458e-04, ..., 6.1362755e-04,\n",
       "        1.2023610e-04, 8.4919208e-08],\n",
       "       [9.0283269e-05, 7.1108201e-07, 6.9276168e-04, ..., 1.3426220e-03,\n",
       "        9.4089482e-05, 7.6597161e-08],\n",
       "       [6.3704669e-05, 6.9787801e-04, 8.6028689e-01, ..., 1.3770338e-03,\n",
       "        4.3710200e-03, 3.3507506e-05],\n",
       "       ...,\n",
       "       [3.9452785e-03, 1.2819510e-04, 1.7320499e-02, ..., 9.5915750e-02,\n",
       "        1.1666388e-03, 1.8871109e-05],\n",
       "       [6.5834211e-05, 2.0830344e-06, 2.5563759e-03, ..., 1.8407014e-03,\n",
       "        2.1673480e-04, 3.2040691e-07],\n",
       "       [3.4165234e-04, 4.3226642e-06, 7.5082318e-04, ..., 2.2828295e-03,\n",
       "        4.8908531e-03, 1.2573242e-06]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comedy', 'drama', 'comedy', ..., 'romance', 'comedy', 'drama'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binarizer.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2799840709960058"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metr.log_loss(label_binarizer.inverse_transform(y_test), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_predict(label_binarizer, probs):\n",
    "    tmp = probs.argmax(axis = 1)\n",
    "    class_dict = dict(enumerate(label_binarizer.classes_))\n",
    "    @np.vectorize\n",
    "    def mapper(label_index):\n",
    "        return class_dict[label_index]\n",
    "    return mapper(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.22      0.17      0.19       209\n",
      "   adventure       0.14      0.08      0.11        96\n",
      "      comedy       0.46      0.38      0.41       692\n",
      "       crime       0.08      0.13      0.10        79\n",
      "       drama       0.44      0.48      0.46       952\n",
      "      horror       0.44      0.38      0.41       216\n",
      "     romance       0.15      0.20      0.17       144\n",
      "    thriller       0.11      0.16      0.13       161\n",
      "     western       0.44      0.34      0.38       122\n",
      "\n",
      "    accuracy                           0.35      2671\n",
      "   macro avg       0.27      0.26      0.26      2671\n",
      "weighted avg       0.37      0.35      0.36      2671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metr.classification_report(label_binarizer.inverse_transform(y_test), \n",
    "                           hard_predict(label_binarizer, y_pred)\n",
    "                          ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcharan/anaconda3/envs/learn37/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7209 samples, validate on 802 samples\n",
      "Epoch 1/1\n",
      "7209/7209 [==============================] - 370s 51ms/step - loss: 1.9180 - accuracy: 0.3267 - val_loss: 1.8541 - val_accuracy: 0.3404\n",
      "371.752 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "# Timer.start()\n",
    "# model.fit(X, y, epochs=1, batch_size=32, validation_split=0.1)\n",
    "# Timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
